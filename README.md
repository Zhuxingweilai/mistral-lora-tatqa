# 从0到1微调一个大语言模型，是一种怎样的体验？

——一名实习生眼中的AI工程世界

### **引言**

过去一年，大语言模型（LLM）成为技术圈最热的关键词。模型参数越堆越大，但企业真正关心的是：我们能不能用一个“小模型”，更精确地解决一个“特定任务”？  
我在一次AI实习项目中，亲手参与了从数据处理、模型微调到部署验证的全过程，尝试基于这个[https://github.com/NExTplusplus/TAT-QA/tree/master/dataset\_raw](https://github.com/NExTplusplus/TAT-QA/tree/master/dataset_raw)问答数据集，训练一个能理解财务报表语境、具备数值推理能力的语言模型。  
本文不谈“AI有多强”，而是记录一个实习生如何用实际工程方法，训练出一个“能完成指定任务”的定制语言模型，以及这个过程中我所看到的AI真实面貌。

* * *

## 一、为什么要微调大语言模型？

大模型的通用能力虽然强，但对具体任务往往“一知半解”，比如你问一个开源模型“2019年该公司Other类销售额较2018年变化多少？”，它可能会答非所问，甚至直接拒答。这是因为它缺乏对任务场景和数据格式的专门训练。  
而微调正是让模型“具备某种专业能力”的过程。  
这次的目标是让模型学会：

- 从带有财务表格和附注的文本中抽取关键信息
- 理解数值和时间的对应关系
- 在表格与文字之间进行交叉推理
- 完成类似 _TatQA_ 这样的财务表格问答任务

* * *

## 二、微调一个模型，要走哪些步骤？

### 1\. 数据构建：从原始文件到 instruction 格式

我使用了自己准备并上传的 **tatqa\_dataset\_dev.json** 数据集，其中包含了大量企业财报片段、表格以及基于它们的问答样例。  
原始数据包含：

- 财务表格（如收入、成本、资产负债表）
- 报表附注文字说明
- 对应的任务型问答（包括直接抽取、计算、比较等）

我用 Python 脚本将这些数据清洗、格式化，并转成如下 **instruction + input + output** 结构：

```
{
  "instruction": "根据表格和文字回答问题",
  "input": "表格：<table>...<table> 附注：... 问题：2019年Other类销售额比2018年变化多少？",
  "output": "-12.6 百万美元"
}
```

这种格式方便模型在微调过程中学习任务模式和推理路径。

* * *

### 2\. 模型选择与技术框架

我尝试了两个方向：

- **phi-4-mini-reasoning**：轻量、高效，适合验证微调流程
- **Mistral-7B-Instruct-v0.2**：参数较大，推理能力强，适合复杂表格推理

核心技术栈：

- HuggingFace Transformers
- PEFT（Parameter Efficient Fine-Tuning）
- LoRA（Low-Rank Adaptation）
- 自定义 RMSNorm 兼容处理
- Trainer + FP16 混合精度优化训练
- 部署调试使用 **LLaMA Factory** 等微调工具，减少底层代码错误的调试负担

训练中多次用到python 脚本，结合 GPU 云电脑(如Azure)环境，通过 Jupyter Lab 和 WebUI 进行调试，在这期间为了便于调试和避免大量代码bug的问题，我选择使用了比如说LLaMA Factory之类的模型微调工具来帮助完成任务，这些模型微调工具恰当使用有利于不熟悉大模型框架的人快速进行微调尝试。

* * *

### 3\. 环境部署：你以为是微调，其实是DevOps

本地部署时踩了无数 PyTorch、Transformers 与 CUDA 版本坑，最后选择云端 GPU 平台，用预装镜像解决环境问题。  
这让我第一次感受到：AI项目不是“跑个脚本”这么简单，它更像是一场跨越数据、算法、系统的协作工程。

* * *

## 三、微调完成后，我学到了什么？

**技术上的成长：**

- 从 0 到 1 搭建了财务问答微调流程
- 掌握了 PEFT、LoRA 配置与调优
- 学会了根据任务类型优化输入结构
- 能够在表格与文本结合的场景下测试模型推理效果

**工程思维的转变：**

- 微调不是让模型“更万能”，而是让它“更专精”
- 数据质量和任务适配度，比模型大小更重要
- 环境搭建与部署能力是AI工程师的必备基础
- 微调只是落地的第一步，后续还要考虑与业务系统的对接（如Function Calling）

* * *

通过这次实习，我完整经历了用**我自己的数据集**塑造模型的过程。  
虽然模型参数不如 GPT-4 庞大，但它能在财报问答上给出更精确的结果——这正是微调的价值所在。
